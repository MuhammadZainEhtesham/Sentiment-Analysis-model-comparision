{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiVQgg1dQ4Z-"
      },
      "outputs": [],
      "source": [
        "#  Run this to ensure TensorFlow 2.x is used\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18n8oFQ8R9dA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Dense,LSTM,Bidirectional,Conv1D,MaxPooling1D,GlobalMaxPooling1D\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "import re\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNDGaSoEUCyn"
      },
      "outputs": [],
      "source": [
        "training_data = pd.read_csv('train.tsv',sep = '\\t')\n",
        "test_data = pd.read_csv('test.tsv',sep = '\\t')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWpTQByzaNTc"
      },
      "outputs": [],
      "source": [
        "training_data = training_data[['Phrase','Sentiment']]\n",
        "test_data = test_data[['Phrase']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0IQI2vyW-c3"
      },
      "outputs": [],
      "source": [
        "def depure_data(data):\n",
        "    \n",
        "    #Removing URLs with a regular expression\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    data = url_pattern.sub(r'', data)\n",
        "\n",
        "    # Remove Emails\n",
        "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
        "\n",
        "    # Remove new line characters\n",
        "    data = re.sub('\\s+', ' ', data)\n",
        "\n",
        "    # Remove distracting single quotes\n",
        "    data = re.sub(\"\\'\", \"\", data)\n",
        "        \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_WwgY7JXADn",
        "outputId": "8a133a3d-1fdf-48e0-b267-5e5423635a09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .',\n",
              " 'A series of escapades demonstrating the adage that what is good for the goose',\n",
              " 'A series',\n",
              " 'A',\n",
              " 'series']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp = []\n",
        "#Splitting pd.Series to list\n",
        "data_to_list = training_data['Phrase'].values.tolist()\n",
        "for i in range(len(data_to_list)):\n",
        "    temp.append(depure_data(data_to_list[i]))\n",
        "list(temp[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uluOy_vbXikh",
        "outputId": "69d76270-c352-4bde-d680-b6d5a255a41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['series', 'of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose', 'is', 'also', 'good', 'for', 'the', 'gander', 'some', 'of', 'which', 'occasionally', 'amuses', 'but', 'none', 'of', 'which', 'amounts', 'to', 'much', 'of', 'story'], ['series', 'of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose'], ['series'], [], ['series'], ['of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose'], ['of'], ['escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose'], ['escapades'], ['demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose']]\n"
          ]
        }
      ],
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "        \n",
        "\n",
        "data_words = list(sent_to_words(temp))\n",
        "\n",
        "print(data_words[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nEMjizJYDtv",
        "outputId": "e6578ab4-41c5-4b4c-ce2c-981f28bba474"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "156060"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ttn8A5AZYTJv"
      },
      "outputs": [],
      "source": [
        "def detokenize(text):\n",
        "    return TreebankWordDetokenizer().detokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIHIutPZYaBm",
        "outputId": "7a883487-6472-4245-8c08-a7987317f54c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['series of escapades demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amounts to much of story', 'series of escapades demonstrating the adage that what is good for the goose', 'series', '', 'series']\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "for i in range(len(data_words)):\n",
        "    data.append(detokenize(data_words[i]))\n",
        "print(data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqRCEXuoZCZ5"
      },
      "outputs": [],
      "source": [
        "data_sent = np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IG6XGK5ZU_z"
      },
      "outputs": [],
      "source": [
        "data_labels = training_data['Sentiment'].values.tolist()\n",
        "data_labels = np.array(data_labels)\n",
        "data_labels = tf.keras.utils.to_categorical(data_labels, 5, dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLV2Fio2V5TR"
      },
      "outputs": [],
      "source": [
        "#play with these to see their effect\n",
        "vocab_size = 5000\n",
        "embedding_dim = 20\n",
        "max_length = 200\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "training_size = 100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDcVVg_fWwIE"
      },
      "outputs": [],
      "source": [
        "def preprocessing(sent_list,labels):\n",
        "  tokenizer = Tokenizer(num_words = vocab_size,oov_token = oov_tok)\n",
        "  tokenizer.fit_on_texts(sent_list)\n",
        "  \n",
        "  word_index = tokenizer.word_index\n",
        "\n",
        "  sent_sequences = tokenizer.texts_to_sequences(sent_list)\n",
        "  sent_padded = pad_sequences(sent_sequences,maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
        "  sent_padded = np.array(sent_padded)\n",
        "  labels = np.array(labels)\n",
        "  return sent_padded,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZLr2CuYa32k"
      },
      "outputs": [],
      "source": [
        "training_sent = data_sent[0:training_size]\n",
        "training_lab = data_labels[0:training_size]\n",
        "val_sent = data_sent[training_size:]\n",
        "val_lab = data_labels[training_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hfw1k9hEZwbO"
      },
      "outputs": [],
      "source": [
        "training_padded,training_labels = preprocessing(training_sent,training_lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyoTdFgPcTOa"
      },
      "outputs": [],
      "source": [
        "val_padded,val_labels = preprocessing(val_sent,val_lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvHhsGkZaF86",
        "outputId": "21f3bc26-5ef0-481d-ccae-c5e3c0bad942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(training_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wapy0LwEccLD"
      },
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Embedding(vocab_size,20))\n",
        "model1.add(LSTM(15,dropout = 0.5))\n",
        "model1.add(Dense(5,activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XuPYRuag7mt"
      },
      "outputs": [],
      "source": [
        "model1.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop',metrics = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1QT3DTCi8Bj",
        "outputId": "432998cf-07f5-4710-e4dc-e466726a1bc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, None, 20)          100000    \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 15)                2160      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102,240\n",
            "Trainable params: 102,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LWSt7cokaA_",
        "outputId": "01ba84c6-73c3-440e-c555-0e58cffdb654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3120/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5179\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49588, saving model to best_model1.hdf5\n",
            "3125/3125 [==============================] - 38s 12ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4218 - val_accuracy: 0.4959\n",
            "Epoch 2/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 2: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4221 - val_accuracy: 0.4959\n",
            "Epoch 3/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 3: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4218 - val_accuracy: 0.4959\n",
            "Epoch 4/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5179\n",
            "Epoch 4: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4220 - val_accuracy: 0.4959\n",
            "Epoch 5/30\n",
            "3121/3125 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 5: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4218 - val_accuracy: 0.4959\n",
            "Epoch 6/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5179\n",
            "Epoch 6: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4219 - val_accuracy: 0.4959\n",
            "Epoch 7/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 7: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4217 - val_accuracy: 0.4959\n",
            "Epoch 8/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 8: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4216 - val_accuracy: 0.4959\n",
            "Epoch 9/30\n",
            "3120/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 9: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4221 - val_accuracy: 0.4959\n",
            "Epoch 10/30\n",
            "3121/3125 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 10: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4220 - val_accuracy: 0.4959\n",
            "Epoch 11/30\n",
            "3121/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5179\n",
            "Epoch 11: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4222 - val_accuracy: 0.4959\n",
            "Epoch 12/30\n",
            "3121/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5179\n",
            "Epoch 12: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4220 - val_accuracy: 0.4959\n",
            "Epoch 13/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 13: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4219 - val_accuracy: 0.4959\n",
            "Epoch 14/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 14: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4218 - val_accuracy: 0.4959\n",
            "Epoch 15/30\n",
            "3121/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 15: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4220 - val_accuracy: 0.4959\n",
            "Epoch 16/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 16: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4223 - val_accuracy: 0.4959\n",
            "Epoch 17/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 17: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4219 - val_accuracy: 0.4959\n",
            "Epoch 18/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 18: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4217 - val_accuracy: 0.4959\n",
            "Epoch 19/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 19: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4218 - val_accuracy: 0.4959\n",
            "Epoch 20/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 20: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4219 - val_accuracy: 0.4959\n",
            "Epoch 21/30\n",
            "3120/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 21: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4221 - val_accuracy: 0.4959\n",
            "Epoch 22/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 22: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4220 - val_accuracy: 0.4959\n",
            "Epoch 23/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 23: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4217 - val_accuracy: 0.4959\n",
            "Epoch 24/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.4130 - accuracy: 0.5178\n",
            "Epoch 24: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4130 - accuracy: 0.5178 - val_loss: 0.4219 - val_accuracy: 0.4959\n",
            "Epoch 25/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 25: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4221 - val_accuracy: 0.4959\n",
            "Epoch 26/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 26: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4220 - val_accuracy: 0.4959\n",
            "Epoch 27/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 27: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4216 - val_accuracy: 0.4959\n",
            "Epoch 28/30\n",
            "3120/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5179\n",
            "Epoch 28: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4222 - val_accuracy: 0.4959\n",
            "Epoch 29/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5179\n",
            "Epoch 29: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 34s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4219 - val_accuracy: 0.4959\n",
            "Epoch 30/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.5178\n",
            "Epoch 30: val_accuracy did not improve from 0.49588\n",
            "3125/3125 [==============================] - 35s 11ms/step - loss: 0.4129 - accuracy: 0.5178 - val_loss: 0.4219 - val_accuracy: 0.4959\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model1.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(val_padded, val_labels), verbose=1,callbacks=[checkpoint1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQBWV8DraTqn"
      },
      "outputs": [],
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Embedding(vocab_size,40,input_length = max_length))\n",
        "model2.add(Bidirectional(LSTM(20,dropout=0.7)))\n",
        "model2.add(Dense(5,activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPwifyXnp50v"
      },
      "outputs": [],
      "source": [
        "model2.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop',metrics = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN_bkjuxp6qU",
        "outputId": "792e6b35-dc57-48b0-9f47-006af3f8612f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 200, 40)           200000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 40)               9760      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 205       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,965\n",
            "Trainable params: 209,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4VK2hC0p-TJ",
        "outputId": "36f814ed-608a-4a85-d77a-4b98fdd24aba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 1.1396 - accuracy: 0.5487\n",
            "Epoch 1: val_accuracy improved from -inf to 0.48109, saving model to best_model1.hdf5\n",
            "3125/3125 [==============================] - 123s 20ms/step - loss: 1.1395 - accuracy: 0.5488 - val_loss: 1.3198 - val_accuracy: 0.4811\n",
            "Epoch 2/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.9998 - accuracy: 0.6031\n",
            "Epoch 2: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.9997 - accuracy: 0.6031 - val_loss: 1.4503 - val_accuracy: 0.4597\n",
            "Epoch 3/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.9459 - accuracy: 0.6251\n",
            "Epoch 3: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.9459 - accuracy: 0.6251 - val_loss: 1.5261 - val_accuracy: 0.4472\n",
            "Epoch 4/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.9222 - accuracy: 0.6350\n",
            "Epoch 4: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 64s 21ms/step - loss: 0.9222 - accuracy: 0.6350 - val_loss: 1.5930 - val_accuracy: 0.4406\n",
            "Epoch 5/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.9101 - accuracy: 0.6402\n",
            "Epoch 5: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.9101 - accuracy: 0.6402 - val_loss: 1.6025 - val_accuracy: 0.4308\n",
            "Epoch 6/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.9038 - accuracy: 0.6422\n",
            "Epoch 6: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 67s 22ms/step - loss: 0.9038 - accuracy: 0.6422 - val_loss: 1.5980 - val_accuracy: 0.4331\n",
            "Epoch 7/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.8977 - accuracy: 0.6444\n",
            "Epoch 7: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8977 - accuracy: 0.6443 - val_loss: 1.6285 - val_accuracy: 0.4358\n",
            "Epoch 8/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.8930 - accuracy: 0.6473\n",
            "Epoch 8: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8930 - accuracy: 0.6473 - val_loss: 1.6836 - val_accuracy: 0.4395\n",
            "Epoch 9/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.8911 - accuracy: 0.6484\n",
            "Epoch 9: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8913 - accuracy: 0.6482 - val_loss: 1.6268 - val_accuracy: 0.4278\n",
            "Epoch 10/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.8864 - accuracy: 0.6505\n",
            "Epoch 10: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8864 - accuracy: 0.6505 - val_loss: 1.6551 - val_accuracy: 0.4377\n",
            "Epoch 11/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.8836 - accuracy: 0.6514\n",
            "Epoch 11: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 65s 21ms/step - loss: 0.8836 - accuracy: 0.6514 - val_loss: 1.6264 - val_accuracy: 0.4323\n",
            "Epoch 12/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.8813 - accuracy: 0.6542\n",
            "Epoch 12: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 68s 22ms/step - loss: 0.8814 - accuracy: 0.6542 - val_loss: 1.6572 - val_accuracy: 0.4265\n",
            "Epoch 13/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.8790 - accuracy: 0.6527\n",
            "Epoch 13: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 66s 21ms/step - loss: 0.8791 - accuracy: 0.6526 - val_loss: 1.6653 - val_accuracy: 0.4284\n",
            "Epoch 14/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.8743 - accuracy: 0.6564\n",
            "Epoch 14: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.8742 - accuracy: 0.6564 - val_loss: 1.6699 - val_accuracy: 0.4266\n",
            "Epoch 15/30\n",
            "3125/3125 [==============================] - ETA: 0s - loss: 0.8736 - accuracy: 0.6584\n",
            "Epoch 15: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8736 - accuracy: 0.6584 - val_loss: 1.6833 - val_accuracy: 0.4378\n",
            "Epoch 16/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.8708 - accuracy: 0.6583\n",
            "Epoch 16: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8707 - accuracy: 0.6583 - val_loss: 1.6851 - val_accuracy: 0.4363\n",
            "Epoch 17/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.8706 - accuracy: 0.6587\n",
            "Epoch 17: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8705 - accuracy: 0.6588 - val_loss: 1.6698 - val_accuracy: 0.4345\n",
            "Epoch 18/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.8665 - accuracy: 0.6593\n",
            "Epoch 18: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.8665 - accuracy: 0.6593 - val_loss: 1.6853 - val_accuracy: 0.4255\n",
            "Epoch 19/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.8659 - accuracy: 0.6600\n",
            "Epoch 19: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.8659 - accuracy: 0.6600 - val_loss: 1.7063 - val_accuracy: 0.4303\n",
            "Epoch 20/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.8638 - accuracy: 0.6619\n",
            "Epoch 20: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.8637 - accuracy: 0.6619 - val_loss: 1.6851 - val_accuracy: 0.4373\n",
            "Epoch 21/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.8630 - accuracy: 0.6618\n",
            "Epoch 21: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8629 - accuracy: 0.6618 - val_loss: 1.6824 - val_accuracy: 0.4282\n",
            "Epoch 22/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.8620 - accuracy: 0.6618\n",
            "Epoch 22: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8619 - accuracy: 0.6618 - val_loss: 1.6989 - val_accuracy: 0.4284\n",
            "Epoch 23/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.8602 - accuracy: 0.6633\n",
            "Epoch 23: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.8603 - accuracy: 0.6633 - val_loss: 1.6711 - val_accuracy: 0.4323\n",
            "Epoch 24/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.8615 - accuracy: 0.6637\n",
            "Epoch 24: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.8614 - accuracy: 0.6638 - val_loss: 1.7007 - val_accuracy: 0.4332\n",
            "Epoch 25/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.8598 - accuracy: 0.6630\n",
            "Epoch 25: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 61s 20ms/step - loss: 0.8599 - accuracy: 0.6630 - val_loss: 1.6823 - val_accuracy: 0.4297\n",
            "Epoch 26/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.8600 - accuracy: 0.6637\n",
            "Epoch 26: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8600 - accuracy: 0.6638 - val_loss: 1.6860 - val_accuracy: 0.4325\n",
            "Epoch 27/30\n",
            "3124/3125 [============================>.] - ETA: 0s - loss: 0.8584 - accuracy: 0.6643\n",
            "Epoch 27: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 63s 20ms/step - loss: 0.8584 - accuracy: 0.6643 - val_loss: 1.6646 - val_accuracy: 0.4231\n",
            "Epoch 28/30\n",
            "3122/3125 [============================>.] - ETA: 0s - loss: 0.8579 - accuracy: 0.6639\n",
            "Epoch 28: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8578 - accuracy: 0.6639 - val_loss: 1.7105 - val_accuracy: 0.4351\n",
            "Epoch 29/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.8589 - accuracy: 0.6657\n",
            "Epoch 29: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8589 - accuracy: 0.6657 - val_loss: 1.6990 - val_accuracy: 0.4279\n",
            "Epoch 30/30\n",
            "3123/3125 [============================>.] - ETA: 0s - loss: 0.8571 - accuracy: 0.6647\n",
            "Epoch 30: val_accuracy did not improve from 0.48109\n",
            "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8572 - accuracy: 0.6647 - val_loss: 1.6924 - val_accuracy: 0.4316\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "checkpoint2 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model2.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(val_padded, val_labels), verbose=1,callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjMlJBrwqEHU"
      },
      "outputs": [],
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Embedding(vocab_size,40,input_length = max_length))\n",
        "model3.add(Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(MaxPooling1D(5))\n",
        "model3.add(Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(GlobalMaxPooling1D())\n",
        "model3.add(Dense(5,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mt_2w9VnDVB"
      },
      "outputs": [],
      "source": [
        "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyfbsLEUnF4k",
        "outputId": "896e6797-f990-494d-cf41-55c45b1651cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3125/3125 [==============================] - 30s 6ms/step - loss: 1.2849 - acc: 0.5193 - val_loss: 1.2819 - val_acc: 0.4967\n",
            "Epoch 2/30\n",
            "3125/3125 [==============================] - 20s 6ms/step - loss: 1.2380 - acc: 0.5239 - val_loss: 1.2793 - val_acc: 0.4978\n",
            "Epoch 3/30\n",
            "3125/3125 [==============================] - 17s 6ms/step - loss: 1.2324 - acc: 0.5264 - val_loss: 1.2877 - val_acc: 0.4966\n",
            "Epoch 4/30\n",
            "3125/3125 [==============================] - 19s 6ms/step - loss: 1.2267 - acc: 0.5300 - val_loss: 1.2914 - val_acc: 0.4963\n",
            "Epoch 5/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.2216 - acc: 0.5318 - val_loss: 1.2873 - val_acc: 0.4919\n",
            "Epoch 6/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.2167 - acc: 0.5337 - val_loss: 1.2966 - val_acc: 0.4918\n",
            "Epoch 7/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.2120 - acc: 0.5360 - val_loss: 1.2908 - val_acc: 0.4927\n",
            "Epoch 8/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.2080 - acc: 0.5389 - val_loss: 1.2963 - val_acc: 0.4911\n",
            "Epoch 9/30\n",
            "3125/3125 [==============================] - 20s 6ms/step - loss: 1.2042 - acc: 0.5415 - val_loss: 1.3066 - val_acc: 0.4890\n",
            "Epoch 10/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.2012 - acc: 0.5434 - val_loss: 1.3128 - val_acc: 0.4814\n",
            "Epoch 11/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1977 - acc: 0.5457 - val_loss: 1.3300 - val_acc: 0.4929\n",
            "Epoch 12/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1947 - acc: 0.5475 - val_loss: 1.3300 - val_acc: 0.4883\n",
            "Epoch 13/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1917 - acc: 0.5491 - val_loss: 1.3266 - val_acc: 0.4872\n",
            "Epoch 14/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1887 - acc: 0.5502 - val_loss: 1.3366 - val_acc: 0.4848\n",
            "Epoch 15/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1858 - acc: 0.5521 - val_loss: 1.3486 - val_acc: 0.4911\n",
            "Epoch 16/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1832 - acc: 0.5535 - val_loss: 1.3421 - val_acc: 0.4893\n",
            "Epoch 17/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1806 - acc: 0.5547 - val_loss: 1.3463 - val_acc: 0.4826\n",
            "Epoch 18/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1782 - acc: 0.5580 - val_loss: 1.3558 - val_acc: 0.4854\n",
            "Epoch 19/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1758 - acc: 0.5595 - val_loss: 1.3454 - val_acc: 0.4805\n",
            "Epoch 20/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1738 - acc: 0.5615 - val_loss: 1.3635 - val_acc: 0.4783\n",
            "Epoch 21/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1715 - acc: 0.5631 - val_loss: 1.3620 - val_acc: 0.4909\n",
            "Epoch 22/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1701 - acc: 0.5631 - val_loss: 1.3665 - val_acc: 0.4837\n",
            "Epoch 23/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1684 - acc: 0.5657 - val_loss: 1.3707 - val_acc: 0.4851\n",
            "Epoch 24/30\n",
            "3125/3125 [==============================] - 19s 6ms/step - loss: 1.1662 - acc: 0.5673 - val_loss: 1.3642 - val_acc: 0.4858\n",
            "Epoch 25/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1649 - acc: 0.5679 - val_loss: 1.3672 - val_acc: 0.4872\n",
            "Epoch 26/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1628 - acc: 0.5695 - val_loss: 1.3796 - val_acc: 0.4867\n",
            "Epoch 27/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1613 - acc: 0.5711 - val_loss: 1.4030 - val_acc: 0.4916\n",
            "Epoch 28/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1599 - acc: 0.5717 - val_loss: 1.3780 - val_acc: 0.4780\n",
            "Epoch 29/30\n",
            "3125/3125 [==============================] - 18s 6ms/step - loss: 1.1585 - acc: 0.5719 - val_loss: 1.3751 - val_acc: 0.4752\n",
            "Epoch 30/30\n",
            "3125/3125 [==============================] - 17s 5ms/step - loss: 1.1574 - acc: 0.5735 - val_loss: 1.3653 - val_acc: 0.4813\n"
          ]
        }
      ],
      "source": [
        "history = model3.fit(training_padded, training_labels, epochs=30, validation_data=(val_padded, val_labels), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11wiMXNWnSCS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}